---
draft: true
date:
  created: 2025-05-01
categories:
  - Summary
tags:
  - Rethingking
  - Adversarial Attack
authors:
  - zhazi
---

# 三维点云对抗攻击反思录(三) —— 数字域攻击与物理域攻击

> 在我开始研究点云对抗的第一天，我的导师就给了我一个似乎很合理的规划：**先研究数字域攻击，然后使用数字域攻击的成果指导物理域攻击实施。**然而，我很快就对“物理域攻击”这一个概念感到困惑。“物理域”的说法暗示了其与“数字域攻击”的联系，甚至隐含了数字域攻击可以拓展为物理域攻击的意思。然而，至少在三维点云对抗领域，我了解到的数物理域工作看起来和数字域上广泛研究的“对抗样本”毫无关联。  

> 具体来说，当提到数字域攻击时，我会想到 KNN, SI-Adv, IF-Defense 等经典的点云对抗攻防研究，这些都是针对点云分类任务的攻击。而提到物理域攻击，一切就立刻变了个画风：有打印自动驾驶系统无法感知到的几何体的、有用激光发射器干扰激光雷达的、有通过车联网传递假消息的等等等等。**这些数字域的攻击怎么可能指导物理域攻击？**  

> 不过辗转在项目和论文中，我很快就学会了忽略这一问题。然而，在磕磕绊绊的走过一年半后，当我对点云对抗有了比较充分的认识后，站在一个新的起点重新回顾这一问题时，我依然会发出 ：“这些数字域的攻击怎么可能指导物理域攻击？”的感叹。事实上，在蹉跎一年多后，我对这个结论越发认可，因此我决定整理并记录下这段时间里的思考，结束这个问题。

!!! info 参考文献

    - [美团内部讲座｜清华大学莫一林：信息物理系统中的安全控制算法](https://tech.meituan.com/2020/09/30/meituan-top-talk-moyilin-cps.html)
    - [信息物理系统 (CPS) 安全洞察分析](https://www.secrss.com/articles/60922)

**TODO**

## 背景

### 数字域攻击

- AI 安全

### 物理域攻击

- 系统安全

### 自动驾驶系统语义 AI 安全

- 研究目标

本质上，导师期望的是一个 AI 安全与系统安全交集中的工作，所以给我的规划是：**先研究数字域攻击，然后使用数字域攻击的成果指导物理域攻击实施。**然而，如上面所见到的，这两者有着极大的差异。

## 研究的差异

### 点云分类 vs. 三维感知

### 扫描点云 vs. 激光雷达点云

### 针对模型的攻击 vs. 针对系统的攻击 

## 思考

- 为什么我一开始会有“数字域攻击都事研究点云分类任务，而物理域攻击都是研究针对自动驾驶系统的攻击”的认识

    1. 论文上的“幸存者偏差”。 点云分类也可以有物理域攻击，三维目标检测也可以有数字域攻击。本质上是，点云分类没有什么现实应用，没有物理域的基础，相关研究只能自娱自乐，论文难发。三维目标检测有明确的应用场景——自动驾驶。相关研究要是只做个数字域，现实意义不够，论文难发。

    2. 没有接触过系统安全领域的论文、理论

- 研究路线？

    1. 数字域可以向大模型对抗过渡。
    2. 物理域直接从系统安全开始做。

- 图像的数字域攻击和点云的数字域攻击有什么不同？

- 物理域上是否有对抗样本的概念？

    可以有。用系统替换模型，用环境替换输入数据，攻击者对环境添加人类难以察觉的扰动，导致系统出错，这里，攻击者修改后的环境，**就是物理域的对抗样本**。相比于传统的研究：

    - 扰动的方式更复杂 $E' = M_{adv}(E)$
    - 扰动的约束更复杂
    - 系统不可微，梯度无法回传
    - 动态的攻击场景

- 数字域上的对抗样本对物理域是否有帮助？

    - 对抗样本是无用的，用于制作对抗样本的攻击算法/理论是有用的
    - 挖掘出的模型的漏洞也是有用的
    - 数字域攻击的研究，能给物理域攻击带来启发的，是算法的设计方式、模型的脆弱性分析等理论上的东西，而不是对抗样本。

- 要做物理域攻击，是先考虑物理域还是先考虑数字域？

    - 先考虑物理域是更合理的选择。因为物理域的事情更复杂。

    - 物理域先行：先设计对抗手段，有一些参数可以调整，然后数字域仿真优化这些参数。
    - 数字域先行：先设计数字域上的对抗样本，然后再逆推出物理域上的扰动。

    - 经典的对抗样本的定义为：“对抗样本是指通过在输入样本中添加微小、人类难以察觉的扰动，导致模型产生错误输出的样本。”，而那些针对神经网络的物理域攻击中，攻击者是通过在物理世界中施加扰动（比如添加物体、改变纹理等）间接影响模型的输入的。难道我们要为了复用数字域上找到的对抗样本，而逆推物理域中的扰动吗？这显然是不合理的，因为攻击者的修改受到物理规律的约束，绝大多数数字域上的对抗样本是物理不可行的。那么我在数字域攻击时考虑物理约束呢？当你这么想的时候，其实你已经否定了数字域上的那批对抗样本，准备制作一批新的对抗样本了！而这思考过程还可以进行下去，我们还要考虑传感器的影响，因此上一批对抗样本又被否定了，我们还要再制作一批新的对抗样本。我们还得考虑输入预处理对对抗样本的影响，天哪！我们一直在制作新的对抗样本。



**TODO 素材**

因为物理世界中的修改到达模型输入空间之前至少会受到物理规则、传感器、输入预处理等
难道我们要通过构建对抗样本然后
这里模型的输入是传感器的扫描结果，而不是攻击者施加了扰动的。

事实上，如果只是要实现对自动驾驶系统的攻击，我并不需要考虑系统中的那些深度神经网络，我完全可以一枪崩了激光雷达完事，而这也是一种物理域攻击（攻击从物理域发起），而且也确实有一类攻击(1)，通过激光发射器干扰雷达从而导致系统出错。而糟糕的是，无论是针对传感器的攻击还是针对神经网络的攻击，都被称为“物理域攻击”。这让我无法理解这个研究领域的目标是什么，要实现物理域的攻击，
{ .annotate }

1. 我通常戏称这类方法为“激光捅雷达”，管他背后是什么神经网络，我直接把激光雷达捅穿了还有你神经网络什么事:sweat_smile:。

在我看来，针对系统的攻击完全可以通过攻击其暴露在外的接口（传感器）来实现，而针对隐藏在系统中的模型的对抗攻击则难以实现，也不一定能起到很好的效果。

但如果把它们划到一块我又不能理解，这篇论文中提出的**语义 AI 安全**，某种程度上解决了我的困惑。

> 依据攻击发起的位置，网络安全攻击可分为数字域攻击和物理域攻击，前者通过数据层面的扰动欺骗系统，后者则直接作用于物理设备或环境，两者在目标、方式和影响上存在显著差异。

> 如果我一开始有知道 CPS 的概念，我想一切会变的很不一样。

> 悟已往之不谏，知来者之可追。实迷途其未远，觉今是而昨非。—— 陶渊明《归去来兮辞》
