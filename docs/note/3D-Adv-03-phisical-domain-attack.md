---
draft: true
date:
  created: 2025-05-01
categories:
  - Summary
tags:
  - Rethingking
  - Adversarial Attack
authors:
  - zhazi
---

# 三维点云对抗攻击反思录(三) —— 物理域攻击


> 几乎是从做点云对抗第一天起，我就对**“物理域攻击”**这一个概念感到困惑。“物理域”的说法暗示了其与**“数字域攻击”**的联系，甚至隐含了**数字域攻击可以拓展为物理域攻击**的意思。然而，至少在自动驾驶安全领域，绝大多数工作看起来和数字域上广泛研究的“对抗样本”毫无关联。

结论：


> 物理域上是否有对抗样本的概念？

可以有。用系统替换模型，用环境替换输入数据，攻击者对环境添加人类难以察觉的扰动，导致系统出错，这里，攻击者修改后的环境，**就是物理域的对抗样本**。相比于传统的研究：

- 扰动的方式更复杂 $E' = M_{adv}(E)$
- 扰动的约束更复杂
- 系统不可微，梯度无法回传
- 动态的攻击场景

> 数字域上的对抗样本对物理域是否有帮助？

- 对抗样本是无用的，用于制作对抗样本的攻击算法/理论是有用的
- 挖掘出的模型的漏洞也是有用的

> 数字域攻击的研究，能给物理域攻击带来启发的，是算法的设计方式、模型的脆弱性分析等理论上的东西，而不是对抗样本。

> 经典的对抗样本的定义为：“对抗样本是指通过在输入样本中添加微小、人类难以察觉的扰动，导致模型产生错误输出的样本。”，而那些针对神经网络的物理域攻击中，攻击者是通过在物理世界中施加扰动（比如添加物体、改变纹理等）间接影响模型的输入的。难道我们要为了复用数字域上找到的对抗样本，而逆推物理域中的扰动吗？这显然是不合理的，因为攻击者的修改受到物理规律的约束，绝大多数数字域上的对抗样本是物理不可行的。那么我在数字域攻击时考虑物理约束呢？当你这么想的时候，其实你已经否定了数字域上的那批对抗样本，准备制作一批新的对抗样本了！而这思考过程还可以进行下去，我们还要考虑传感器的影响，因此上一批对抗样本又被否定了，我们还要再制作一批新的对抗样本。我们还得考虑输入预处理对对抗样本的影响，天哪！我们一直在制作新的对抗样本。



**TODO**
因为物理世界中的修改到达模型输入空间之前至少会受到物理规则、传感器、输入预处理等
难道我们要通过构建对抗样本然后
这里模型的输入是传感器的扫描结果，而不是攻击者施加了扰动的。

事实上，如果只是要实现对自动驾驶系统的攻击，我并不需要考虑系统中的那些深度神经网络，我完全可以一枪崩了激光雷达完事，而这也是一种物理域攻击（攻击从物理域发起），而且也确实有一类攻击(1)，通过激光发射器干扰雷达从而导致系统出错。而糟糕的是，无论是针对传感器的攻击还是针对神经网络的攻击，都被称为“物理域攻击”。这让我无法理解这个研究领域的目标是什么，要实现物理域的攻击，
{ .annotate }

1. 我通常戏称这类方法为“激光捅雷达”，管他背后是什么神经网络，我直接把激光雷达捅穿了还有你神经网络什么事:sweat_smile:。

在我看来，针对系统的攻击完全可以通过攻击其暴露在外的接口（传感器）来实现，而针对隐藏在系统中的模型的对抗攻击则难以实现，也不一定能起到很好的效果。

但如果把它们划到一块我又不能理解，这篇论文中提出的**语义 AI 安全**，某种程度上解决了我的困惑。
